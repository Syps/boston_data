{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_TYPE_DESCRIPTION</th>\n",
       "      <th>FROMDATE</th>\n",
       "      <th>WEAPONTYPE</th>\n",
       "      <th>Shooting</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESIDENTIAL BURGLARY</td>\n",
       "      <td>07/08/2012 06:00:00 AM</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34638135, -71.10379454)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGGRAVATED ASSAULT</td>\n",
       "      <td>07/08/2012 06:03:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.31684135, -71.07458456)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>07/08/2012 06:26:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34284135, -71.09698955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMMERCIAL BURGLARY</td>\n",
       "      <td>07/08/2012 06:56:00 AM</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.3164411, -71.06582908)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>07/08/2012 07:15:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.27051636, -71.11989955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>07/08/2012 07:32:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.31328183, -71.0530059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>07/08/2012 07:50:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.32425136, -71.08620956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SIMPLE ASSAULT</td>\n",
       "      <td>07/08/2012 07:50:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34924634, -71.06378456)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MedAssist</td>\n",
       "      <td>07/08/2012 07:53:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.35174635, -71.16590953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MedAssist</td>\n",
       "      <td>07/08/2012 08:05:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.25938275, -71.11729354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BENoProp</td>\n",
       "      <td>07/08/2012 08:10:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34180635, -71.09707955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VAL</td>\n",
       "      <td>07/08/2012 08:15:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.3092417, -71.05033304)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FRAUD</td>\n",
       "      <td>07/08/2012 09:00:00 AM</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34924634, -71.06378456)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PropFound</td>\n",
       "      <td>07/08/2012 09:30:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.33490135, -71.07516956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>InvPer</td>\n",
       "      <td>07/08/2012 09:30:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.35973634, -71.06796956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TOWED</td>\n",
       "      <td>07/08/2012 09:45:00 AM</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.34456135, -71.13768454)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VAL</td>\n",
       "      <td>07/08/2012 09:47:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.36179134, -71.05277456)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOWED</td>\n",
       "      <td>07/08/2012 09:53:00 AM</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.33637135, -71.04348957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WEAPONS CHARGE</td>\n",
       "      <td>07/08/2012 09:55:00 AM</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.32170135, -71.08190956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvProp</td>\n",
       "      <td>07/08/2012 10:00:00 AM</td>\n",
       "      <td>Unarmed</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(42.33747731, -71.08062448)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INCIDENT_TYPE_DESCRIPTION                FROMDATE WEAPONTYPE Shooting  \\\n",
       "0       RESIDENTIAL BURGLARY  07/08/2012 06:00:00 AM      Other       No   \n",
       "1         AGGRAVATED ASSAULT  07/08/2012 06:03:00 AM    Firearm      Yes   \n",
       "2                    ROBBERY  07/08/2012 06:26:00 AM    Firearm       No   \n",
       "3        COMMERCIAL BURGLARY  07/08/2012 06:56:00 AM      Other       No   \n",
       "4                    ROBBERY  07/08/2012 07:15:00 AM    Firearm       No   \n",
       "5                    ROBBERY  07/08/2012 07:32:00 AM    Firearm      Yes   \n",
       "6                    ROBBERY  07/08/2012 07:50:00 AM    Firearm       No   \n",
       "7             SIMPLE ASSAULT  07/08/2012 07:50:00 AM    Unarmed       No   \n",
       "8                  MedAssist  07/08/2012 07:53:00 AM    Unarmed       No   \n",
       "9                  MedAssist  07/08/2012 08:05:00 AM    Unarmed       No   \n",
       "10                  BENoProp  07/08/2012 08:10:00 AM    Unarmed       No   \n",
       "11                       VAL  07/08/2012 08:15:00 AM    Unarmed       No   \n",
       "12                     FRAUD  07/08/2012 09:00:00 AM      Other       No   \n",
       "13                 PropFound  07/08/2012 09:30:00 AM    Unarmed       No   \n",
       "14                    InvPer  07/08/2012 09:30:00 AM    Unarmed       No   \n",
       "15                     TOWED  07/08/2012 09:45:00 AM      Other       No   \n",
       "16                       VAL  07/08/2012 09:47:00 AM    Unarmed       No   \n",
       "17                     TOWED  07/08/2012 09:53:00 AM      Other       No   \n",
       "18            WEAPONS CHARGE  07/08/2012 09:55:00 AM    Firearm       No   \n",
       "19                   InvProp  07/08/2012 10:00:00 AM    Unarmed       No   \n",
       "\n",
       "   DOMESTIC  Year Month DAY_WEEK                     Location  \n",
       "0        No  2012     7   Sunday  (42.34638135, -71.10379454)  \n",
       "1        No  2012     7   Sunday  (42.31684135, -71.07458456)  \n",
       "2        No  2012     7   Sunday  (42.34284135, -71.09698955)  \n",
       "3        No  2012     7   Sunday   (42.3164411, -71.06582908)  \n",
       "4        No  2012     7   Sunday  (42.27051636, -71.11989955)  \n",
       "5        No  2012     7   Sunday   (42.31328183, -71.0530059)  \n",
       "6        No  2012     7   Sunday  (42.32425136, -71.08620956)  \n",
       "7        No  2012     7   Sunday  (42.34924634, -71.06378456)  \n",
       "8        No  2012     7   Sunday  (42.35174635, -71.16590953)  \n",
       "9        No  2012     7   Sunday  (42.25938275, -71.11729354)  \n",
       "10       No  2012     7   Sunday  (42.34180635, -71.09707955)  \n",
       "11       No  2012     7   Sunday   (42.3092417, -71.05033304)  \n",
       "12       No  2012     7   Sunday  (42.34924634, -71.06378456)  \n",
       "13       No  2012     7   Sunday  (42.33490135, -71.07516956)  \n",
       "14       No  2012     7   Sunday  (42.35973634, -71.06796956)  \n",
       "15       No  2012     7   Sunday  (42.34456135, -71.13768454)  \n",
       "16       No  2012     7   Sunday  (42.36179134, -71.05277456)  \n",
       "17       No  2012     7   Sunday  (42.33637135, -71.04348957)  \n",
       "18       No  2012     7   Sunday  (42.32170135, -71.08190956)  \n",
       "19       No  2012     7   Sunday  (42.33747731, -71.08062448)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# somerville happiness data\n",
    "happy = pd.read_csv('somerville_happy.csv')\n",
    "happy.columns = [\n",
    "            'ID', 'Year', 'Current Happy',\n",
    "           'Overall Life Satisfaction',\n",
    "           'Somerville Satisfaction',\n",
    "           'Individual Similarity To Acquaitances 2011',\n",
    "           'Rely on advice or self for decision making 2011',\n",
    "           'Neighborhood satisfaction',\n",
    "           'Proud to be Somerville resident 2015',\n",
    "           'City Services Availability Rating 2015',\n",
    "           'Availability of affordable housing 2011',\n",
    "           'Cost of Housing Rating',\n",
    "           'Rate cost of public schools 2011',\n",
    "           'Rate overall cost of public schools 2011',\n",
    "           'Rate beauty or physical setting 2011',\n",
    "           'Rate beauty or physical setting 2013',\n",
    "           'Rate effectiveness of local police 2011_2013',\n",
    "           'Trust in local police 2015',\n",
    "           'Rate maintenance of streets, sidewalks and squares 2013',\n",
    "           'Rate maintenance of streets, sidewalks and squares 2015',\n",
    "           'Availability of social communities and events',\n",
    "           'Safety walking in neighborhood at night 2013',\n",
    "           'Safety walking in community at night 2015',\n",
    "           'Rate beauty or physical setting of neighborhood 2015',\n",
    "           'Satisfaction with appearance of parks and squares 2013',\n",
    "           'Satisfaction with local parks and squares',\n",
    "           'Gender', 'Gender 2011', 'Age',\n",
    "           'marital status 2011',\n",
    "           'Household languages (non-english) 2015',\n",
    "           'Ethnicity 2011_2013',\n",
    "           'Is Hispanic 2013',\n",
    "           'Ethnicity 2015',\n",
    "           'Lives with Minors',\n",
    "           'Housing Status',\n",
    "           'Plans to leave Somerville within 2 years',\n",
    "           'Years Lived in Somerville',\n",
    "           'Annual Household Income',\n",
    "           'Neighborhood', 'Is Student', 'Ward',\n",
    "           'Precinct'\n",
    "    ]\n",
    "\n",
    "def normalize_income(income):\n",
    "    if income == 'Less than $10,000':\n",
    "        return income\n",
    "    \n",
    "    if income in ['$25,000 to $49,999', '40,000 - $49,999',\n",
    "                  '$10,000 to $24,999', '30,000 - $39,999',\n",
    "                  '20,000 - $29,999', '10,000 - $19,999'\n",
    "                  ]:\n",
    "        return '<50k'\n",
    "    elif income in ['50,000 - $59,999', '60,000 - $69,999',\n",
    "                   '70,000 - $79,999', '80,000 - $89,999',\n",
    "                   '90,000 - $99,999', '$50,000 to $74,999',\n",
    "                   '$75,000 to $99,999']:\n",
    "        return '50k-100k'\n",
    "    else:\n",
    "        return '>100k'\n",
    "    \n",
    "def norm_eth(eth):\n",
    "    ethnicity = eth.split(',')[0].split('/')[0].strip()\n",
    "    if 'white' in ethnicity or 'asian' in ethnicity:\n",
    "        if 'black' in ethnicity or 'African-American' in ethnicity:\n",
    "            return 'black'\n",
    "        return 'white/asian'\n",
    "    elif 'Black' in ethnicity or 'African-American' in ethnicity:\n",
    "        return 'Black'\n",
    "    elif 'R' == ethnicity:\n",
    "        return None\n",
    "    elif 'American Indian' == ethnicity:\n",
    "        return 'Native American'\n",
    "    else:\n",
    "        return ethnicity\n",
    "\n",
    "    \n",
    "\n",
    "happy['Income Bracket'] = happy['Annual Household Income'].apply(normalize_income)\n",
    "happy['ETHNICITY'] = (happy[['Ethnicity 2011_2013', 'Ethnicity 2015']]\n",
    "                      .fillna('')\n",
    "                      .sum(axis=1)\n",
    "                      .apply(norm_eth))\n",
    "\n",
    "\n",
    "\n",
    "def get_income_data():\n",
    "    incomes = pd.DataFrame(happy[happy['Year'] == 2011]['Income Bracket'].value_counts())\n",
    "    incomes['2015'] = happy[happy['Year'] == 2015]['Income Bracket'].value_counts().sort_index()\n",
    "    incomes.columns = ['2011', '2015']\n",
    "    incomes['2011 %'] = incomes['2011'].apply(lambda x: x/float(incomes['2011'].sum()))\n",
    "    incomes['2015 %'] = incomes['2015'].apply(lambda x: x/float(incomes['2015'].sum()))\n",
    "    return incomes\n",
    "\n",
    "def get_happy_data(year, income_bracket):\n",
    "    # happiness data\n",
    "    # happy[(happy['Year'] == 2015) & (happy['Income Bracket'] == '<50k')]['Current Happy'].mean()\n",
    "    current_happy = (happy\n",
    "        .where((happy['Year'] == year) & (happy['Income Bracket'] == income_bracket))\n",
    "        ['Overall Life Satisfaction']\n",
    "        .value_counts()\n",
    "        .sort_index()\n",
    "        .reset_index())\n",
    "    current_happy['index'] = pd.to_numeric(current_happy['index'], \n",
    "                                           errors='coerce')\n",
    "    current_happy['Overall Life Satisfaction'] = pd.to_numeric(current_happy['Overall Life Satisfaction'], \n",
    "                                           errors='coerce')\n",
    "\n",
    "    current_happy = (current_happy\n",
    "     .dropna()\n",
    "     .where(current_happy['index'] < 11)\n",
    "     .dropna(how='any')\n",
    "     .sort_index())\n",
    "\n",
    "    current_happy['Less than 6'] = current_happy['index'].apply(lambda x: x < 6)\n",
    "    current_happy.groupby('Less than 6').sum()\n",
    "    \n",
    "writer = pd.ExcelWriter('happy_cleaned.xls')\n",
    "happy.to_excel(writer, 'Sheet1')\n",
    "get_income_data().to_excel(writer, 'Sheet2')\n",
    "writer.save()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " BOYLSTON ST                     112\n",
       " WASHINGTON ST                    91\n",
       "00 MASSACHUSETTS AV               88\n",
       "618 SHAWMUT AV                    86\n",
       "500 GENEVA AV                     54\n",
       " TREMONT ST                       54\n",
       "00 WASHINGTON ST                  54\n",
       "279 CENTRE ST                     49\n",
       "00 TREMONT ST                     49\n",
       "00 SHAWMUT AV                     44\n",
       "9 DITMUS CT                       37\n",
       "54 ANNUNCIATION RD                34\n",
       " COLUMBIA RD                      32\n",
       " BOWER ST                         29\n",
       "18 LATTIMORE CT                   26\n",
       "934 PARKER ST                     24\n",
       "00 BOYLSTON ST                    22\n",
       " MT PLEASANT AV                   22\n",
       "200 HANCOCK ST                    21\n",
       " BLUE HILL AV                     20\n",
       "4 WAKULLAH ST                     20\n",
       "70 ANNUNCIATION RD                19\n",
       " HARRISON AV                      19\n",
       " ESSEX ST                         18\n",
       "60 ANNUNCIATION RD                18\n",
       "00 ALBANY ST                      18\n",
       "00 COLUMBUS AV                    17\n",
       "00 MELNEA CASS BL                 17\n",
       " MAVERICK SQ                      16\n",
       "301 CENTRE ST                     16\n",
       "                                ... \n",
       "46  CENTRE ST                      1\n",
       "191 FOREST HILLS ST                1\n",
       "49 W SELDEN ST                     1\n",
       "431 MARLBOROUGH ST                 1\n",
       "346 NEWBURY ST                     1\n",
       " EVANS ST at THETFORD AV           1\n",
       "572 COLUMBIA RD                    1\n",
       " ELDER ST at EASTMAN ST            1\n",
       "OPP 87 DAKOTA ST                   1\n",
       "3069 WASHINGTON ST                 1\n",
       "500 BLUE HILL AV                   1\n",
       "0 DORCHESTER ST at W BROADWAY      1\n",
       " ARBORETUM RD                      1\n",
       "423    SARATOGA ST                 1\n",
       " W MAIN ST at HARVARD ST           1\n",
       "15 GORHAM ST                       1\n",
       "46 PORT NORFOLK ST                 1\n",
       "12 MT PLEASANT AV                  1\n",
       " B ST                              1\n",
       "00 W BROADWAY                      1\n",
       " HANCOCK ST at PLEASANT ST         1\n",
       " NORFOLK AV at LANGDON ST          1\n",
       "35 BETHUNE WY                      1\n",
       "1580 DORCHESTER AV                 1\n",
       "956 BLUE HILL AV                   1\n",
       "117 WEBSTER ST                     1\n",
       "0 MOAKLEY PARK                     1\n",
       " MAGAZINE ST at DUDLEY ST          1\n",
       "42 HARVARD AV                      1\n",
       "236 DUDLEY ST                      1\n",
       "Name: LOCATION, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_age_bracket(age):\n",
    "    if age < 13 or age > 80:\n",
    "        return None\n",
    "    if age < 18:\n",
    "        return '<18'\n",
    "    if age < 30:\n",
    "        return '18 - 30'\n",
    "    \n",
    "    return ' 30+'\n",
    "        \n",
    "\n",
    "fio = pd.read_csv('bpd_fio.csv')\n",
    "\n",
    "# init columns\n",
    "fio['FRISKED'] = fio['OUTCOME'].astype(str).apply(lambda x: x.find('F') != -1)\n",
    "fio['SEIZED'] = fio['OUTCOME'].astype(str).apply(lambda x: x.find('S') != -1)\n",
    "fio['AGE_BRACKET'] = fio['AGE_AT_FIO_CORRECTED'].apply(get_age_bracket)\n",
    "fio['YEAR'] = fio['FIO_DATE'].apply(lambda x: x[6:10])\n",
    "fio['MONTH'] = fio['FIO_DATE'].apply(lambda x: x[0:2])\n",
    "fio['DAY'] = fio['FIO_DATE'].apply(lambda x: x[3:5])\n",
    "\n",
    "#total stop breakdown\n",
    "fio[fio['YEAR'] == '2015']['LOCATION'].value_counts()\n",
    "# % black\n",
    "# fio.RACE_DESC.value_counts() / len(fio.index)\n",
    "\n",
    "# # % black by neighborhood\n",
    "# (fio.groupby(['CITY', 'RACE_DESC']).size() / fio.groupby(['CITY']).size()).sort_values(ascending=False)\n",
    "\n",
    "# # city-wide makeup w/ no priors\n",
    "# no_priors = fio[fio['PRIORS'] == 'NO']\n",
    "# no_priors.RACE_DESC.value_counts() / len(no_priors.index)\n",
    "# # neighborhood dist with no priors\n",
    "# (no_priors.groupby(['CITY', 'RACE_DESC']).size() / no_priors.groupby(['CITY']).size())\n",
    "# # city dist w/ priors\n",
    "# has_priors = fio[fio['PRIORS'] == 'YES']\n",
    "# has_priors.RACE_DESC.value_counts() / len(has_priors.index)\n",
    "# # stop reasons\n",
    "# (fio.groupby(['RACE_DESC', 'BASIS']).size() / fio.groupby('RACE_DESC').size())\n",
    "# # terrorism\n",
    "# t = fio[fio.TERRORISM == 'YES']\n",
    "# t.groupby(['RACE_DESC', 'STOP_REASONS']).size()\n",
    "# # % w/ priors by race *** black people that were stopped more likely to have priors\n",
    "# (fio.groupby(['RACE_DESC', 'PRIORS']).size() / fio.groupby('RACE_DESC').size())\n",
    "# # age distribution - median age is 25\n",
    "# fio.AGE_AT_FIO_CORRECTED.median()\n",
    "# # median age by race - blacks have lowest median age (24) & whites have the highest (31)\n",
    "# fio[(~fio['AGE_BRACKET'].isnull()) & (fio['YEAR'] == '2015')].groupby('RACE_DESC').agg('median')['AGE_AT_FIO_CORRECTED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shootings2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Back Bay</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dorchester</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downtown</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East Boston</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyde Park</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jamaica Plain</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longwood Medical Area</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mattapan</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mission Hill</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roslindale</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roxbury</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Boston</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Shootings2015\n",
       "Neighborhood                        \n",
       "Back Bay                           1\n",
       "Dorchester                        41\n",
       "Downtown                           1\n",
       "East Boston                        2\n",
       "Hyde Park                          5\n",
       "Jamaica Plain                      6\n",
       "Longwood Medical Area              2\n",
       "Mattapan                           8\n",
       "Mission Hill                       3\n",
       "Roslindale                         3\n",
       "Roxbury                           26\n",
       "South Boston                       1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crime_data = pd.read_csv('crime_july2012-august2015.csv', dtype='unicode')\n",
    "\n",
    "# with open('site/public/json/neighborhoods.json') as f:\n",
    "#     js = json.load(f)\n",
    "\n",
    "# polygons = [shape(feature['geometry']) for feature in js['features']]\n",
    "# def get_neighborhood(x):\n",
    "#     lat, lon, count = x[0], x[1], x[2]\n",
    "#     if count % 500 == 0:\n",
    "#         print(count)\n",
    "#     point = Point(lon, lat)\n",
    "#         # check each polygon to see if it contains the point\n",
    "#     for i, polygon in enumerate(polygons):\n",
    "#         if polygon.contains(point):\n",
    "#             return js['features'][i]['properties']['Name']\n",
    "        \n",
    "#     return None\n",
    "            \n",
    "# crime_data['location_lat'] = crime_data['Location'].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "# crime_data['location_lon'] = crime_data['Location'].apply(lambda x: float(x.split(',')[-1][:-1]))\n",
    "# crime_data['count'] = crime_data.reset_index().index\n",
    "# crime_data['Neighborhood'] = crime_data[['location_lat', 'location_lon', 'count']].apply(get_neighborhood, axis=1)\n",
    "# crime_data.columns[:]\n",
    "shootings_2015 = crime_data[(crime_data['Year'] == '2015') & (crime_data['Shooting'] == 'Yes')]\n",
    "shootings_2015 = pd.DataFrame(shootings_2015.Neighborhood.value_counts()).sort_index()\n",
    "shootings_2015 = shootings_2015.reset_index()\n",
    "shootings_2015.columns = ['Neighborhood', 'Shootings2015']\n",
    "shootings_2015 = shootings_2015.set_index('Neighborhood')\n",
    "shootings_2015\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# crime_data_2015.to_csv('crime_data_2015.csv', sep='@')\n",
    "def is_violent(row):\n",
    "    desc, weapon = row\n",
    "    if 'Assault' in desc or 'ASSAULT' in desc:\n",
    "        return True\n",
    "    elif weapon not in ['None', 'Unarmed', 'Other']:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "crime_data['violent'] = crime_data[['INCIDENT_TYPE_DESCRIPTION', 'WEAPONTYPE']].apply(is_violent, axis=1)\n",
    "crime_data[(crime_data['Year'] == '2015') & (crime_data['Neighborhood'] == 'Back Bay') & (crime_data['violent'] == True)]\n",
    "\n",
    "crime_data.to_csv('crime_data_cleaned.csv', sep='@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime_data_2015 = pd.read_csv('crime_data_cleaned.csv', sep='@').where(crime_data['Year'] == '2015')\n",
    "violent_crimes = (pd.DataFrame(crime_data_2015[crime_data_2015['violent'] == True]\n",
    "                              .Neighborhood\n",
    "                              .value_counts())\n",
    "                            .reset_index())\n",
    "\n",
    "\n",
    "violent_crimes.columns = ['Neighborhood', 'Violent Crimes']\n",
    "violent_crimes = violent_crimes.set_index('Neighborhood').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id</th>\n",
       "      <th>GEO.id2</th>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th>HD01_VD01</th>\n",
       "      <th>HD02_VD01</th>\n",
       "      <th>HD01_VD02</th>\n",
       "      <th>HD02_VD02</th>\n",
       "      <th>HD01_VD03</th>\n",
       "      <th>HD02_VD03</th>\n",
       "      <th>HD01_VD04</th>\n",
       "      <th>...</th>\n",
       "      <th>HD01_VD06</th>\n",
       "      <th>HD02_VD06</th>\n",
       "      <th>HD01_VD07</th>\n",
       "      <th>HD02_VD07</th>\n",
       "      <th>HD01_VD08</th>\n",
       "      <th>HD02_VD08</th>\n",
       "      <th>HD01_VD09</th>\n",
       "      <th>HD02_VD09</th>\n",
       "      <th>HD01_VD10</th>\n",
       "      <th>HD02_VD10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>Id2</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Estimate; Total:</td>\n",
       "      <td>Margin of Error; Total:</td>\n",
       "      <td>Estimate; Total: - White alone</td>\n",
       "      <td>Margin of Error; Total: - White alone</td>\n",
       "      <td>Estimate; Total: - Black or African American a...</td>\n",
       "      <td>Margin of Error; Total: - Black or African Ame...</td>\n",
       "      <td>Estimate; Total: - American Indian and Alaska ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Estimate; Total: - Native Hawaiian and Other P...</td>\n",
       "      <td>Margin of Error; Total: - Native Hawaiian and ...</td>\n",
       "      <td>Estimate; Total: - Some other race alone</td>\n",
       "      <td>Margin of Error; Total: - Some other race alone</td>\n",
       "      <td>Estimate; Total: - Two or more races:</td>\n",
       "      <td>Margin of Error; Total: - Two or more races:</td>\n",
       "      <td>Estimate; Total: - Two or more races: - Two ra...</td>\n",
       "      <td>Margin of Error; Total: - Two or more races: -...</td>\n",
       "      <td>Estimate; Total: - Two or more races: - Two ra...</td>\n",
       "      <td>Margin of Error; Total: - Two or more races: -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US25025000100</td>\n",
       "      <td>25025000100</td>\n",
       "      <td>Census Tract 1, Suffolk County, Massachusetts</td>\n",
       "      <td>3671</td>\n",
       "      <td>364</td>\n",
       "      <td>2348</td>\n",
       "      <td>390</td>\n",
       "      <td>178</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>556</td>\n",
       "      <td>393</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US25025000201</td>\n",
       "      <td>25025000201</td>\n",
       "      <td>Census Tract 2.01, Suffolk County, Massachusetts</td>\n",
       "      <td>3284</td>\n",
       "      <td>325</td>\n",
       "      <td>2729</td>\n",
       "      <td>300</td>\n",
       "      <td>143</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>106</td>\n",
       "      <td>88</td>\n",
       "      <td>106</td>\n",
       "      <td>77</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US25025000202</td>\n",
       "      <td>25025000202</td>\n",
       "      <td>Census Tract 2.02, Suffolk County, Massachusetts</td>\n",
       "      <td>3587</td>\n",
       "      <td>493</td>\n",
       "      <td>2342</td>\n",
       "      <td>396</td>\n",
       "      <td>365</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>295</td>\n",
       "      <td>324</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US25025000301</td>\n",
       "      <td>25025000301</td>\n",
       "      <td>Census Tract 3.01, Suffolk County, Massachusetts</td>\n",
       "      <td>2712</td>\n",
       "      <td>367</td>\n",
       "      <td>2146</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>154</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GEO.id      GEO.id2  \\\n",
       "0                    Id          Id2   \n",
       "1  1400000US25025000100  25025000100   \n",
       "2  1400000US25025000201  25025000201   \n",
       "3  1400000US25025000202  25025000202   \n",
       "4  1400000US25025000301  25025000301   \n",
       "\n",
       "                                  GEO.display-label         HD01_VD01  \\\n",
       "0                                         Geography  Estimate; Total:   \n",
       "1     Census Tract 1, Suffolk County, Massachusetts              3671   \n",
       "2  Census Tract 2.01, Suffolk County, Massachusetts              3284   \n",
       "3  Census Tract 2.02, Suffolk County, Massachusetts              3587   \n",
       "4  Census Tract 3.01, Suffolk County, Massachusetts              2712   \n",
       "\n",
       "                 HD02_VD01                       HD01_VD02  \\\n",
       "0  Margin of Error; Total:  Estimate; Total: - White alone   \n",
       "1                      364                            2348   \n",
       "2                      325                            2729   \n",
       "3                      493                            2342   \n",
       "4                      367                            2146   \n",
       "\n",
       "                               HD02_VD02  \\\n",
       "0  Margin of Error; Total: - White alone   \n",
       "1                                    390   \n",
       "2                                    300   \n",
       "3                                    396   \n",
       "4                                    320   \n",
       "\n",
       "                                           HD01_VD03  \\\n",
       "0  Estimate; Total: - Black or African American a...   \n",
       "1                                                178   \n",
       "2                                                143   \n",
       "3                                                365   \n",
       "4                                                 50   \n",
       "\n",
       "                                           HD02_VD03  \\\n",
       "0  Margin of Error; Total: - Black or African Ame...   \n",
       "1                                                151   \n",
       "2                                                117   \n",
       "3                                                188   \n",
       "4                                                 36   \n",
       "\n",
       "                                           HD01_VD04  \\\n",
       "0  Estimate; Total: - American Indian and Alaska ...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                           HD01_VD06  \\\n",
       "0  Estimate; Total: - Native Hawaiian and Other P...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                                           HD02_VD06  \\\n",
       "0  Margin of Error; Total: - Native Hawaiian and ...   \n",
       "1                                                 12   \n",
       "2                                                 12   \n",
       "3                                                 12   \n",
       "4                                                 12   \n",
       "\n",
       "                                  HD01_VD07  \\\n",
       "0  Estimate; Total: - Some other race alone   \n",
       "1                                       556   \n",
       "2                                       106   \n",
       "3                                       295   \n",
       "4                                       154   \n",
       "\n",
       "                                         HD02_VD07  \\\n",
       "0  Margin of Error; Total: - Some other race alone   \n",
       "1                                              393   \n",
       "2                                               88   \n",
       "3                                              324   \n",
       "4                                              116   \n",
       "\n",
       "                               HD01_VD08  \\\n",
       "0  Estimate; Total: - Two or more races:   \n",
       "1                                     58   \n",
       "2                                    106   \n",
       "3                                     35   \n",
       "4                                      0   \n",
       "\n",
       "                                      HD02_VD08  \\\n",
       "0  Margin of Error; Total: - Two or more races:   \n",
       "1                                            55   \n",
       "2                                            77   \n",
       "3                                            44   \n",
       "4                                            12   \n",
       "\n",
       "                                           HD01_VD09  \\\n",
       "0  Estimate; Total: - Two or more races: - Two ra...   \n",
       "1                                                 14   \n",
       "2                                                 36   \n",
       "3                                                 15   \n",
       "4                                                  0   \n",
       "\n",
       "                                           HD02_VD09  \\\n",
       "0  Margin of Error; Total: - Two or more races: -...   \n",
       "1                                                 20   \n",
       "2                                                 44   \n",
       "3                                                 34   \n",
       "4                                                 12   \n",
       "\n",
       "                                           HD01_VD10  \\\n",
       "0  Estimate; Total: - Two or more races: - Two ra...   \n",
       "1                                                 44   \n",
       "2                                                 70   \n",
       "3                                                 20   \n",
       "4                                                  0   \n",
       "\n",
       "                                           HD02_VD10  \n",
       "0  Margin of Error; Total: - Two or more races: -...  \n",
       "1                                                 52  \n",
       "2                                                 59  \n",
       "3                                                 31  \n",
       "4                                                 12  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census = pd.read_csv('ma_census_2015.csv', dtype='unicode', skiprows=1)\n",
    "tract_data = pd.read_csv('tract_data.csv', delimiter=' ')\n",
    "# pop = pd.read_csv('pop_total.csv', dtype='unicode', skiprows=1)\n",
    "race = pd.read_csv('race_hispanic.csv', skiprows=1)\n",
    "\n",
    "\n",
    "def get_tract_id(label):\n",
    "    s = label.split(',')\n",
    "    return s[0][12:]\n",
    "\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    \"\"\" \n",
    "    http://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns\n",
    "    \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()\n",
    "\n",
    "def pct(group, num):\n",
    "    n = group[num]\n",
    "    d = group['pop']\n",
    "    return n.sum() / d.sum()\n",
    "    \n",
    "census['tract'] = census['Geography'].apply(get_tract_id)\n",
    "census = (census\n",
    "          .rename(columns = {'Id2':'GEOID'})\n",
    "          .set_index('GEOID'))\n",
    "\n",
    "# population data\n",
    "# pop = (pop\n",
    "#           .rename(columns = {'Id2':'GEOID'})\n",
    "#           .set_index('GEOID'))\n",
    "# pop = pd.DataFrame(pop['Estimate; Total'])\n",
    "\n",
    "#race data\n",
    "race = (race\n",
    "          .rename(columns = {'Id2':'GEOID'})\n",
    "          .set_index('GEOID'))\n",
    "\n",
    "race.columns\n",
    "race = race[[\n",
    "        'Estimate; Total:',\n",
    "       u'Estimate; Not Hispanic or Latino: - White alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - Black or African American alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - American Indian and Alaska Native alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - Asian alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - Native Hawaiian and Other Pacific Islander alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - Some other race alone',\n",
    "       u'Estimate; Not Hispanic or Latino: - Two or more races:',\n",
    "         'Estimate; Hispanic or Latino:'\n",
    "    ]]\n",
    "\n",
    "race_columns = ['pop', 'White', 'Black', 'AmericanIndianNativeAlaskan', 'Asian', 'NativeHawaiianPacificIslander',\n",
    "                'OtherRace', 'TwoOrMoreRaces', 'HispanicLatino']\n",
    "race.columns = race_columns\n",
    "\n",
    "race = race.set_index(race.index.astype(str))\n",
    "\n",
    "# census tract -> neighhborhood map\n",
    "tract_data['GEOID'] = tract_data['GEOID'].astype(str)\n",
    "tract_data = tract_data.set_index('GEOID')\n",
    "\n",
    "# join above\n",
    "census = census.join(tract_data, how='inner')\n",
    "census\n",
    "census = census[['Neighborhood', 'tract',\n",
    "                 'Percent; EMPLOYMENT STATUS - Population 16 years and over - In labor force - Civilian labor force - Unemployed', \n",
    "                 'Percent; PERCENTAGE OF FAMILIES AND PEOPLE WHOSE INCOME IN THE PAST 12 MONTHS IS BELOW THE POVERTY LEVEL - All families'\n",
    "                ]]\n",
    "census.columns = ['Neighborhood', 'tract', 'unemployment rate', 'percent families below poverty level']\n",
    "census = census.join(race, how='inner').replace('-', np.nan)\n",
    "\n",
    "census[['pop', 'unemployment rate', 'percent families below poverty level']] = census[['pop', 'unemployment rate', 'percent families below poverty level']].astype(float)\n",
    "\n",
    "# weighted avg percents to get neighborhood percents\n",
    "employment_by_neighborhood = census.groupby('Neighborhood').apply(wavg, 'unemployment rate', 'pop')\n",
    "poverty_by_neighborhood = census.groupby('Neighborhood').apply(wavg, 'percent families below poverty level', 'pop')\n",
    "\n",
    "\n",
    "# calculate percentage\n",
    "\n",
    "avgs = pd.DataFrame(employment_by_neighborhood, columns=['unemploymentPct'])\n",
    "avgs['povertyPct'] = poverty_by_neighborhood\n",
    "avgs['pop'] = census.groupby('Neighborhood').sum()['pop']\n",
    "avgs = avgs.reset_index()\n",
    "avgs['Neighborhood'] = avgs['Neighborhood'].apply(lambda x: x.replace('_', ' '))\n",
    "avgs = avgs.set_index('Neighborhood').sort_index()\n",
    "\n",
    "avgs = avgs.join(violent_crimes, how='inner')\n",
    "avgs['violentCrimePerCapita'] = avgs['Violent Crimes'] / avgs['pop']\n",
    "avgs['violentCrimesPerThousandPpl'] = avgs['violentCrimePerCapita'] * 1000\n",
    "avgs['shootings'] = shootings_2015['Shootings2015']\n",
    "\n",
    "\n",
    "race_totals = census.groupby('Neighborhood').sum()[race_columns].reset_index()\n",
    "race_totals['Neighborhood'] = race_totals['Neighborhood'].apply(lambda x: x.replace('_', ' '))\n",
    "race_totals = race_totals.set_index('Neighborhood').sort_index()\n",
    "\n",
    "for race in race_columns:\n",
    "    if race == 'pop':\n",
    "        continue\n",
    "    col_name = race.lower() + 'Pct'\n",
    "    avgs[col_name] = (race_totals[race] / race_totals['pop']) * 100\n",
    "\n",
    "ranked_cols = ['unemploymentPct', 'povertyPct', 'violentCrimePerCapita']\n",
    "\n",
    "for col in ranked_cols:\n",
    "    avgs[\"{}Rank\".format(col)] = avgs[col].rank(ascending=False)\n",
    "    \n",
    "avgs.to_csv('site/public/csv/averages_2015.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
